---
title: "Software 2.0"
date: 2018-10-11
classes: wide
tags: [software 2.0, test]
---

Andrej Karpathy gave a talk at the Pytorch Developer Conference on "Software 2.0" a term he has been using recently to describe a new programming paradigm where the programming is done by machine learning.  I remember previously, seeing or reading, something by Andrej about Software 2.0 where he described its thesis, so I was already familiar with the idea and its merit.  This new talk, however, was a sort of engineering best pratices talk including: TDD, CI, and version control equivalents in Software 2.0.  The talk was rather short only 10 minutes so he couldn't cover a lot; but it raised a question for me which I think is a reasonable one and somewhat an implicit conclusion of his talk. Namely, Randomization considered harmful?  This is somewhat startling if true considering how pervasive randomization is found throughout the machine learning stack: weight initialization, batching, and optimaztion/training all have elements of randomization. 



|  x1 |  x2 |  x3 |  y  |
| --- | --- | --- | --- |
|  0  |  0  |  0  |  0  |
|  0  |  1  |  0  |  1  |
|  1  |  0  |  0  |  1  |
|  1  |  1  |  1  |  0  |

where: y = x1 XOR x2

  and: x3 = x1 * x2 